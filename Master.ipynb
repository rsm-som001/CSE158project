{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import html\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132303, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#image_id</th>\n",
       "      <th>unixtime</th>\n",
       "      <th>rawtime</th>\n",
       "      <th>title</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>reddit_id</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>number_of_downvotes</th>\n",
       "      <th>localtime</th>\n",
       "      <th>score</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333172e+09</td>\n",
       "      <td>2012-03-31T12:40:39.590113-07:00</td>\n",
       "      <td>And here's a downvote.</td>\n",
       "      <td>63470.0</td>\n",
       "      <td>rmqjs</td>\n",
       "      <td>32657.0</td>\n",
       "      <td>funny</td>\n",
       "      <td>30813.0</td>\n",
       "      <td>1.333198e+09</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>Animates_Everything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333178e+09</td>\n",
       "      <td>2012-03-31T14:16:01.093638-07:00</td>\n",
       "      <td>Expectation</td>\n",
       "      <td>35.0</td>\n",
       "      <td>rmun4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.333203e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gangsta_Raper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333200e+09</td>\n",
       "      <td>2012-03-31T20:18:33.192906-07:00</td>\n",
       "      <td>Downvote</td>\n",
       "      <td>41.0</td>\n",
       "      <td>rna86</td>\n",
       "      <td>32.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.333225e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gangsta_Raper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333252e+09</td>\n",
       "      <td>2012-04-01T10:52:10-07:00</td>\n",
       "      <td>Every time I downvote something</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ro7e4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.333278e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gangsta_Raper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333273e+09</td>\n",
       "      <td>2012-04-01T16:35:54.393381-07:00</td>\n",
       "      <td>Downvote &amp;quot;Dies Irae&amp;quot;</td>\n",
       "      <td>65.0</td>\n",
       "      <td>rooof</td>\n",
       "      <td>57.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.333298e+09</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gangsta_Raper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #image_id      unixtime                           rawtime  \\\n",
       "0          0  1.333172e+09  2012-03-31T12:40:39.590113-07:00   \n",
       "1          0  1.333178e+09  2012-03-31T14:16:01.093638-07:00   \n",
       "2          0  1.333200e+09  2012-03-31T20:18:33.192906-07:00   \n",
       "3          0  1.333252e+09         2012-04-01T10:52:10-07:00   \n",
       "4          0  1.333273e+09  2012-04-01T16:35:54.393381-07:00   \n",
       "\n",
       "                             title  total_votes reddit_id  number_of_upvotes  \\\n",
       "0           And here's a downvote.      63470.0     rmqjs            32657.0   \n",
       "1                      Expectation         35.0     rmun4               29.0   \n",
       "2                         Downvote         41.0     rna86               32.0   \n",
       "3  Every time I downvote something         10.0     ro7e4                6.0   \n",
       "4   Downvote &quot;Dies Irae&quot;         65.0     rooof               57.0   \n",
       "\n",
       "  subreddit  number_of_downvotes     localtime   score  number_of_comments  \\\n",
       "0     funny              30813.0  1.333198e+09  1844.0               622.0   \n",
       "1  GifSound                  6.0  1.333203e+09    23.0                 3.0   \n",
       "2  GifSound                  9.0  1.333225e+09    23.0                 0.0   \n",
       "3  GifSound                  4.0  1.333278e+09     2.0                 0.0   \n",
       "4  GifSound                  8.0  1.333298e+09    49.0                 0.0   \n",
       "\n",
       "              username  \n",
       "0  Animates_Everything  \n",
       "1        Gangsta_Raper  \n",
       "2        Gangsta_Raper  \n",
       "3        Gangsta_Raper  \n",
       "4        Gangsta_Raper  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/andrewchen/CSE158/Assignment_2/redditSubmissions.csv.gz\",\n",
    "    compression=\"gzip\",\n",
    "    on_bad_lines=\"skip\",\n",
    "    engine=\"python\"\n",
    ")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEN'S EDA IS RIGHT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## however many cells needed. Note the structure of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Validation\n",
    "\n",
    "Before building any models, we first validate that the core numeric fields in the dataset are internally consistent and that there are no obvious data quality issues.\n",
    "\n",
    "**Checks performed:**\n",
    "\n",
    "1. **Score consistency**\n",
    "   We verify that the Reddit `score` field matches the definition:\n",
    "      `score` = `number_of_upvotes` - `number_of_downvotes`\n",
    "\n",
    "2. **Non-negative votes**\n",
    "\n",
    "   We confirm that `number_of_upvotes` and `number_of_downvotes` are never negative.  \n",
    "\n",
    "3. **Duplicated posts**\n",
    "\n",
    "   Using `reddit_id` as the unique identifier of a submission, we check for duplicated `reddit_id`s.  \n",
    "\n",
    "4. **Missing values**\n",
    "\n",
    "   Finally, we compute the total number of missing values in the dataset\n",
    "      - The `username` column has 20,260 missing values, but will not be considered in our model\n",
    "      - Every other column only has 1 missing value on the same row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score consistency check (should be 0): 0.0\n",
      "Number of rows with negative votes (should be 0): 0\n",
      "Number of duplicated reddit_id values: 93\n",
      "#image_id                  0\n",
      "unixtime                   1\n",
      "rawtime                    1\n",
      "title                      1\n",
      "total_votes                1\n",
      "reddit_id                  1\n",
      "number_of_upvotes          1\n",
      "subreddit                  1\n",
      "number_of_downvotes        1\n",
      "localtime                  1\n",
      "score                      1\n",
      "number_of_comments         1\n",
      "username               20260\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Score = upvotes - downvotes\n",
    "score_diff = (df['number_of_upvotes'] - df['number_of_downvotes'] - df['score']).abs().sum()\n",
    "print(\"Score consistency check (should be 0):\", score_diff)\n",
    "\n",
    "# Non-negative votes\n",
    "\n",
    "neg_votes = ((df['number_of_upvotes'] < 0) | (df['number_of_downvotes'] < 0)).sum()\n",
    "print(\"Number of rows with negative votes (should be 0):\", neg_votes)\n",
    "\n",
    "dup_count = df['reddit_id'].duplicated().sum()\n",
    "print(\"Number of duplicated reddit_id values:\", dup_count)\n",
    "\n",
    "# Missing Values\n",
    "df_nan = df.isna().sum()\n",
    "print(df_nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated reddit_id values: 0\n",
      "Number of NANs: 0\n"
     ]
    }
   ],
   "source": [
    "# Casting \n",
    "df['unixtime'] = pd.to_numeric(df['unixtime'], errors='coerce')\n",
    "df['datetime'] = pd.to_datetime(df['unixtime'], unit='s')\n",
    "df['total_votes'] = df['total_votes'].astype(float)\n",
    "df['number_of_upvotes'] = df['number_of_upvotes'].astype(float)\n",
    "df['number_of_downvotes'] = df['number_of_downvotes'].astype(float)\n",
    "df['score'] = df['score'].astype(float)\n",
    "\n",
    "# Duplicate Handling \n",
    "df = df.drop_duplicates(subset=['reddit_id'])\n",
    "dup_reddit_ids = df['reddit_id'].duplicated().sum()\n",
    "print(\"Number of duplicated reddit_id values:\", dup_reddit_ids)\n",
    "\n",
    "# Missing Values Handling\n",
    "df = df.drop(columns=['username'])\n",
    "df = df.dropna()\n",
    "print('Number of NANs:', df.isna().sum().sum())\n",
    "\n",
    "\n",
    "def clean_title(text):\n",
    "    # 1. Ensure string\n",
    "    s = str(text)\n",
    "    # 2. Unescape HTML entities: &quot; &amp; &lt; &gt; etc.\n",
    "    s = html.unescape(s)\n",
    "    # 3. Strip leading/trailing whitespace\n",
    "    s = s.strip()\n",
    "    # 4. Collapse multiple spaces/newlines into a single space\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    # 5. (Optional) lowercase for modeling\n",
    "    s = s.lower()\n",
    "    return s\n",
    "df['title_clean'] = df['title'].apply(clean_title)\n",
    "df['title'] = df['title_clean']\n",
    "df.drop(columns=['title_clean'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Because Reddit scores are extremely heavy-tailed, even after a log-transform the top 1–5% of posts still had disproportionate influence and caused numerically unstable predictions.\n",
    "\n",
    "## We removed the top 5% of scores to make the distribution more well-behaved. After this, log-space MAE improved significantly and raw-space MAE became interpretable and stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p95 = df['score'].quantile(0.95)\n",
    "df = df[df['score'] <= p95].copy()\n",
    "\n",
    "\n",
    "# this move massively improved our model\n",
    "\n",
    "# i dont have a graph but i'm pretty sure the values towards the top are astronomically large "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125598, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#image_id</th>\n",
       "      <th>unixtime</th>\n",
       "      <th>rawtime</th>\n",
       "      <th>title</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>reddit_id</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>number_of_downvotes</th>\n",
       "      <th>localtime</th>\n",
       "      <th>score</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333178e+09</td>\n",
       "      <td>2012-03-31T14:16:01.093638-07:00</td>\n",
       "      <td>expectation</td>\n",
       "      <td>35.0</td>\n",
       "      <td>rmun4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.333203e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-03-31 07:16:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333200e+09</td>\n",
       "      <td>2012-03-31T20:18:33.192906-07:00</td>\n",
       "      <td>downvote</td>\n",
       "      <td>41.0</td>\n",
       "      <td>rna86</td>\n",
       "      <td>32.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.333225e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-03-31 13:18:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333252e+09</td>\n",
       "      <td>2012-04-01T10:52:10-07:00</td>\n",
       "      <td>every time i downvote something</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ro7e4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.333278e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-04-01 03:52:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333273e+09</td>\n",
       "      <td>2012-04-01T16:35:54.393381-07:00</td>\n",
       "      <td>downvote \"dies irae\"</td>\n",
       "      <td>65.0</td>\n",
       "      <td>rooof</td>\n",
       "      <td>57.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.333298e+09</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-04-01 09:35:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333761e+09</td>\n",
       "      <td>2012-04-07T08:11:00-07:00</td>\n",
       "      <td>demolished, every time you downvote someone</td>\n",
       "      <td>40.0</td>\n",
       "      <td>rxwjg</td>\n",
       "      <td>17.0</td>\n",
       "      <td>gifs</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.333786e+09</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-04-07 01:11:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #image_id      unixtime                           rawtime  \\\n",
       "1          0  1.333178e+09  2012-03-31T14:16:01.093638-07:00   \n",
       "2          0  1.333200e+09  2012-03-31T20:18:33.192906-07:00   \n",
       "3          0  1.333252e+09         2012-04-01T10:52:10-07:00   \n",
       "4          0  1.333273e+09  2012-04-01T16:35:54.393381-07:00   \n",
       "5          0  1.333761e+09         2012-04-07T08:11:00-07:00   \n",
       "\n",
       "                                         title  total_votes reddit_id  \\\n",
       "1                                  expectation         35.0     rmun4   \n",
       "2                                     downvote         41.0     rna86   \n",
       "3              every time i downvote something         10.0     ro7e4   \n",
       "4                         downvote \"dies irae\"         65.0     rooof   \n",
       "5  demolished, every time you downvote someone         40.0     rxwjg   \n",
       "\n",
       "   number_of_upvotes subreddit  number_of_downvotes     localtime  score  \\\n",
       "1               29.0  GifSound                  6.0  1.333203e+09   23.0   \n",
       "2               32.0  GifSound                  9.0  1.333225e+09   23.0   \n",
       "3                6.0  GifSound                  4.0  1.333278e+09    2.0   \n",
       "4               57.0  GifSound                  8.0  1.333298e+09   49.0   \n",
       "5               17.0      gifs                 23.0  1.333786e+09   -6.0   \n",
       "\n",
       "   number_of_comments            datetime  \n",
       "1                 3.0 2012-03-31 07:16:01  \n",
       "2                 0.0 2012-03-31 13:18:33  \n",
       "3                 0.0 2012-04-01 03:52:10  \n",
       "4                 0.0 2012-04-01 09:35:54  \n",
       "5                 3.0 2012-04-07 01:11:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "df['title'] = df['title'].astype(str).str.strip()\n",
    "df['title_length'] = df['title'].apply(len)\n",
    "df['word_count'] = df['title'].apply(lambda x: len(x.split()))\n",
    "df['is_question'] = df['title'].str.contains('?', regex=False).astype(int)\n",
    "df['is_exclamation'] = df['title'].str.contains('!', regex=False).astype(int)\n",
    "\n",
    "\n",
    "# Adding subreddit stats - I did not include subreddit stats as I believe it leaks the target variable\n",
    "# subreddit_stats = df.groupby('subreddit')['score'].agg(\n",
    "#     subreddit_mean_score='mean',\n",
    "#     subreddit_post_count='count'\n",
    "# ).reset_index()\n",
    "# df = df.merge(subreddit_stats, on='subreddit', how='left')\n",
    "\n",
    "# Adding sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def add_title_sentiment(df):\n",
    "    titles = df['title'].astype(str)\n",
    "\n",
    "    scores = titles.apply(sia.polarity_scores) \n",
    "    scores_df = scores.apply(pd.Series)\n",
    "\n",
    "    df['title_sent_neg'] = scores_df['neg']\n",
    "    df['title_sent_neu'] = scores_df['neu']\n",
    "    df['title_sent_pos'] = scores_df['pos']\n",
    "    df['title_sent_compound'] = scores_df['compound']\n",
    "    return df\n",
    "# add new column\n",
    "df = add_title_sentiment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#image_id</th>\n",
       "      <th>unixtime</th>\n",
       "      <th>rawtime</th>\n",
       "      <th>title</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>reddit_id</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>number_of_downvotes</th>\n",
       "      <th>localtime</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>title_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>is_question</th>\n",
       "      <th>is_exclamation</th>\n",
       "      <th>title_sent_neg</th>\n",
       "      <th>title_sent_neu</th>\n",
       "      <th>title_sent_pos</th>\n",
       "      <th>title_sent_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333178e+09</td>\n",
       "      <td>2012-03-31T14:16:01.093638-07:00</td>\n",
       "      <td>expectation</td>\n",
       "      <td>35.0</td>\n",
       "      <td>rmun4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.333203e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333200e+09</td>\n",
       "      <td>2012-03-31T20:18:33.192906-07:00</td>\n",
       "      <td>downvote</td>\n",
       "      <td>41.0</td>\n",
       "      <td>rna86</td>\n",
       "      <td>32.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.333225e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333252e+09</td>\n",
       "      <td>2012-04-01T10:52:10-07:00</td>\n",
       "      <td>every time i downvote something</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ro7e4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.333278e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333273e+09</td>\n",
       "      <td>2012-04-01T16:35:54.393381-07:00</td>\n",
       "      <td>downvote \"dies irae\"</td>\n",
       "      <td>65.0</td>\n",
       "      <td>rooof</td>\n",
       "      <td>57.0</td>\n",
       "      <td>GifSound</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.333298e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.333761e+09</td>\n",
       "      <td>2012-04-07T08:11:00-07:00</td>\n",
       "      <td>demolished, every time you downvote someone</td>\n",
       "      <td>40.0</td>\n",
       "      <td>rxwjg</td>\n",
       "      <td>17.0</td>\n",
       "      <td>gifs</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.333786e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132298</th>\n",
       "      <td>9998</td>\n",
       "      <td>1.344760e+09</td>\n",
       "      <td>2012-08-12T15:24:06-07:00</td>\n",
       "      <td>om nom nom</td>\n",
       "      <td>34.0</td>\n",
       "      <td>y41wv</td>\n",
       "      <td>25.0</td>\n",
       "      <td>funny</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.344785e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132299</th>\n",
       "      <td>9998</td>\n",
       "      <td>1.345270e+09</td>\n",
       "      <td>2012-08-18T13:09:38-07:00</td>\n",
       "      <td>don't feed the animals...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>yfw66</td>\n",
       "      <td>14.0</td>\n",
       "      <td>funny</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.345295e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132300</th>\n",
       "      <td>9998</td>\n",
       "      <td>1.345954e+09</td>\n",
       "      <td>2012-08-26T04:06:02+00:00</td>\n",
       "      <td>wtf worthy.</td>\n",
       "      <td>49.0</td>\n",
       "      <td>yu838</td>\n",
       "      <td>26.0</td>\n",
       "      <td>WTF</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.345954e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132301</th>\n",
       "      <td>9998</td>\n",
       "      <td>1.346626e+09</td>\n",
       "      <td>2012-09-02T22:45:06+00:00</td>\n",
       "      <td>just a camel eating a kids head, welcome to th...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>z91ah</td>\n",
       "      <td>65.0</td>\n",
       "      <td>WTF</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.346626e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132302</th>\n",
       "      <td>9998</td>\n",
       "      <td>1.347718e+09</td>\n",
       "      <td>2012-09-15T14:00:43+00:00</td>\n",
       "      <td>ass is looking at a little girl eaten by camel.</td>\n",
       "      <td>425.0</td>\n",
       "      <td>zxbsj</td>\n",
       "      <td>272.0</td>\n",
       "      <td>WTF</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1.347718e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125598 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        #image_id      unixtime                           rawtime  \\\n",
       "1               0  1.333178e+09  2012-03-31T14:16:01.093638-07:00   \n",
       "2               0  1.333200e+09  2012-03-31T20:18:33.192906-07:00   \n",
       "3               0  1.333252e+09         2012-04-01T10:52:10-07:00   \n",
       "4               0  1.333273e+09  2012-04-01T16:35:54.393381-07:00   \n",
       "5               0  1.333761e+09         2012-04-07T08:11:00-07:00   \n",
       "...           ...           ...                               ...   \n",
       "132298       9998  1.344760e+09         2012-08-12T15:24:06-07:00   \n",
       "132299       9998  1.345270e+09         2012-08-18T13:09:38-07:00   \n",
       "132300       9998  1.345954e+09         2012-08-26T04:06:02+00:00   \n",
       "132301       9998  1.346626e+09         2012-09-02T22:45:06+00:00   \n",
       "132302       9998  1.347718e+09         2012-09-15T14:00:43+00:00   \n",
       "\n",
       "                                                    title  total_votes  \\\n",
       "1                                             expectation         35.0   \n",
       "2                                                downvote         41.0   \n",
       "3                         every time i downvote something         10.0   \n",
       "4                                    downvote \"dies irae\"         65.0   \n",
       "5             demolished, every time you downvote someone         40.0   \n",
       "...                                                   ...          ...   \n",
       "132298                                         om nom nom         34.0   \n",
       "132299                          don't feed the animals...         19.0   \n",
       "132300                                        wtf worthy.         49.0   \n",
       "132301  just a camel eating a kids head, welcome to th...        123.0   \n",
       "132302    ass is looking at a little girl eaten by camel.        425.0   \n",
       "\n",
       "       reddit_id  number_of_upvotes subreddit  number_of_downvotes  \\\n",
       "1          rmun4               29.0  GifSound                  6.0   \n",
       "2          rna86               32.0  GifSound                  9.0   \n",
       "3          ro7e4                6.0  GifSound                  4.0   \n",
       "4          rooof               57.0  GifSound                  8.0   \n",
       "5          rxwjg               17.0      gifs                 23.0   \n",
       "...          ...                ...       ...                  ...   \n",
       "132298     y41wv               25.0     funny                  9.0   \n",
       "132299     yfw66               14.0     funny                  5.0   \n",
       "132300     yu838               26.0       WTF                 23.0   \n",
       "132301     z91ah               65.0       WTF                 58.0   \n",
       "132302     zxbsj              272.0       WTF                153.0   \n",
       "\n",
       "           localtime  ...  month  is_weekend title_length  word_count  \\\n",
       "1       1.333203e+09  ...      3           1           11           1   \n",
       "2       1.333225e+09  ...      3           1            8           1   \n",
       "3       1.333278e+09  ...      4           1           31           5   \n",
       "4       1.333298e+09  ...      4           1           20           3   \n",
       "5       1.333786e+09  ...      4           1           43           6   \n",
       "...              ...  ...    ...         ...          ...         ...   \n",
       "132298  1.344785e+09  ...      8           1           10           3   \n",
       "132299  1.345295e+09  ...      8           1           25           4   \n",
       "132300  1.345954e+09  ...      8           1           11           2   \n",
       "132301  1.346626e+09  ...      9           1           56          11   \n",
       "132302  1.347718e+09  ...      9           1           47          10   \n",
       "\n",
       "        is_question  is_exclamation  title_sent_neg  title_sent_neu  \\\n",
       "1                 0               0           0.000           1.000   \n",
       "2                 0               0           0.000           1.000   \n",
       "3                 0               0           0.000           1.000   \n",
       "4                 0               0           0.000           1.000   \n",
       "5                 0               0           0.000           1.000   \n",
       "...             ...             ...             ...             ...   \n",
       "132298            0               0           0.000           1.000   \n",
       "132299            0               0           0.000           1.000   \n",
       "132300            0               0           0.567           0.000   \n",
       "132301            0               0           0.000           0.769   \n",
       "132302            0               0           0.280           0.720   \n",
       "\n",
       "        title_sent_pos  title_sent_compound  \n",
       "1                0.000               0.0000  \n",
       "2                0.000               0.0000  \n",
       "3                0.000               0.0000  \n",
       "4                0.000               0.0000  \n",
       "5                0.000               0.0000  \n",
       "...                ...                  ...  \n",
       "132298           0.000               0.0000  \n",
       "132299           0.000               0.0000  \n",
       "132300           0.433              -0.2263  \n",
       "132301           0.231               0.4588  \n",
       "132302           0.000              -0.5423  \n",
       "\n",
       "[125598 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up X,y for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (100478, 18)\n",
      "Test shape: (25120, 18)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----- 1. Define X and y -----\n",
    "\n",
    "# Features\n",
    "text_features = ['title']\n",
    "cat_features = ['subreddit']\n",
    "num_features = [\n",
    "    'total_votes',\n",
    "    'number_of_upvotes',\n",
    "    'number_of_downvotes',\n",
    "    'number_of_comments',\n",
    "    'hour',\n",
    "    'dayofweek',\n",
    "    'month',\n",
    "    'is_weekend',\n",
    "    'title_length',\n",
    "    'word_count',\n",
    "    'is_question',\n",
    "    'is_exclamation',\n",
    "    'title_sent_neg',\n",
    "    'title_sent_neu',\n",
    "    'title_sent_pos',\n",
    "    'title_sent_compound',\n",
    "]\n",
    "\n",
    "feature_cols = text_features + cat_features + num_features\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "\n",
    "# Target: use log(1 + score) to stabilize heavy tails\n",
    "y_raw = df['score']\n",
    "min_score = y_raw.min()\n",
    "# shift so that the minimum becomes 1, then log-transform\n",
    "y_shifted = y_raw - min_score + 1\n",
    "y_log = np.log(y_shifted)\n",
    "\n",
    "# ----- 2. Train / test split: 80 / 20 -----\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_log,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1: Predict Global Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE (log space): 0.3695\n",
      "Baseline MAE (raw score): 174.5136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 1. Baseline in log space\n",
    "mean_pred = y_train.mean()\n",
    "y_test_pred_log = np.full_like(y_test, mean_pred, dtype=float)\n",
    "\n",
    "# 2. Inverse-transform both true and predicted values back to raw score\n",
    "y_test_raw = np.exp(y_test) + min_score - 1\n",
    "y_test_pred_raw = np.exp(y_test_pred_log) + min_score - 1\n",
    "\n",
    "# 3. MAE in original score units (upvotes minus downvotes)\n",
    "baseline_mae_raw = mean_absolute_error(y_test_raw, y_test_pred_raw)\n",
    "\n",
    "print(f\"Baseline MAE (log space): {mean_absolute_error(y_test, y_test_pred_log):.4f}\")\n",
    "print(f\"Baseline MAE (raw score): {baseline_mae_raw:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2: Predict Subreddit Mean with Global Mean fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test MAE  (log):  0.3479\n",
      "  Test MAE  (raw):  167.0088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ---- Baseline 2: Subreddit mean (with fallback to global mean) ----\n",
    "\n",
    "# 1. Compute mean *log-score* per subreddit on TRAIN ONLY\n",
    "train_df_for_means = pd.DataFrame({\n",
    "    \"subreddit\": X_train[\"subreddit\"].values,\n",
    "    \"score_log\": y_train  # y_train is already log-transformed\n",
    "})\n",
    "\n",
    "subreddit_means_log = train_df_for_means.groupby(\"subreddit\")[\"score_log\"].mean()\n",
    "\n",
    "# Global mean in log space (used as fallback for unseen subreddits)\n",
    "global_mean_log = y_train.mean()\n",
    "\n",
    "def predict_subreddit_mean_log(X, subreddit_means_log, global_mean_log):\n",
    "    \"\"\"\n",
    "    For each row in X, predict the mean *log-score* of its subreddit,\n",
    "    falling back to the global mean (log) if the subreddit was unseen in training.\n",
    "    \"\"\"\n",
    "    return X[\"subreddit\"].map(subreddit_means_log).fillna(global_mean_log).values\n",
    "\n",
    "# 2. Predictions on TEST set (log space)\n",
    "y_test_pred_log = predict_subreddit_mean_log(X_test, subreddit_means_log, global_mean_log)\n",
    "\n",
    "# 3. Metrics in LOG space\n",
    "mae_log = mean_absolute_error(y_test, y_test_pred_log)\n",
    "\n",
    "# 4. Inverse transform both true and predicted back to RAW score space\n",
    "# recall: y_log = log(score - min_score + 1)\n",
    "y_test_raw = np.exp(y_test) + min_score - 1\n",
    "y_test_pred_raw = np.exp(y_test_pred_log) + min_score - 1\n",
    "\n",
    "mae_raw = mean_absolute_error(y_test_raw, y_test_pred_raw)\n",
    "\n",
    "print(f\"  Test MAE  (log):  {mae_log:.4f}\")\n",
    "print(f\"  Test MAE  (raw):  {mae_raw:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with TF-IDF + Metadata Featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test MAE  (log): 0.0766\n",
      "  Test MAE  (raw): 43.0519\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "RANDOM_STATE = 42  # for CV shuffling\n",
    "\n",
    "lin_feature_cols = text_features + cat_features + num_features\n",
    "\n",
    "X_train_lin = X_train[lin_feature_cols].copy()\n",
    "X_test_lin  = X_test[lin_feature_cols].copy()\n",
    "\n",
    "text_col = \"title\"\n",
    "cat_cols  = cat_features\n",
    "num_cols  = num_features\n",
    "\n",
    "preprocessor_lin = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"text\",\n",
    "            TfidfVectorizer(\n",
    "                max_features=20000,\n",
    "                ngram_range=(1, 2),\n",
    "                min_df=5\n",
    "            ),\n",
    "            text_col,\n",
    "        ),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "            cat_cols,\n",
    "        ),\n",
    "        (\n",
    "            \"num\",\n",
    "            StandardScaler(),\n",
    "            num_cols,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "\n",
    "lin_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor_lin),\n",
    "        (\"model\", lin_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5 fold CV for consistency\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    lin_pipeline,\n",
    "    X_train_lin,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "\n",
    "lin_pipeline.fit(X_train_lin, y_train)\n",
    "\n",
    "# Predictions in log space\n",
    "y_test_pred_log_lin = lin_pipeline.predict(X_test_lin)\n",
    "\n",
    "# Log-space metrics\n",
    "lin_mae_log  = mean_absolute_error(y_test, y_test_pred_log_lin)\n",
    "\n",
    "# Inverse-transform back to raw score space\n",
    "y_test_raw = np.exp(y_test) + min_score - 1\n",
    "y_test_pred_raw_lin = np.exp(y_test_pred_log_lin) + min_score - 1\n",
    "\n",
    "lin_mae_raw  = mean_absolute_error(y_test_raw, y_test_pred_raw_lin)\n",
    "\n",
    "print(f\"  Test MAE  (log): {lin_mae_log:.4f}\")\n",
    "print(f\"  Test MAE  (raw): {lin_mae_raw:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Champion Model: Ridge Regression with TF-IDF + Metadata Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Ridge MAE (log): 0.06883936243843784\n",
      "Ridge MAE (raw): 40.03342035932269\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "ridge_feature_cols = text_features + cat_features + num_features\n",
    "\n",
    "X_train_ridge = X_train[ridge_feature_cols].copy()\n",
    "X_test_ridge = X_test[ridge_feature_cols].copy()\n",
    "\n",
    "\n",
    "text_col = \"title\"\n",
    "cat_cols = cat_features\n",
    "num_cols = num_features\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"text\",\n",
    "            TfidfVectorizer(\n",
    "                max_features=20000,\n",
    "                ngram_range=(1, 2),\n",
    "                min_df=5\n",
    "            ),\n",
    "            text_col,\n",
    "        ),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "            cat_cols,\n",
    "        ),\n",
    "        (\n",
    "            \"num\",\n",
    "            StandardScaler(),\n",
    "            num_cols,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5 fold CV\n",
    "base_ridge = Ridge(random_state=RANDOM_STATE)\n",
    "\n",
    "ridge_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", base_ridge),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__alpha\": [0.01, 0.1, 1, 3, 10, 30, 100]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=ridge_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",   #!!!! MAE in LOG space\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# y_train is log-transformed already!!!!! dont forget \n",
    "grid.fit(X_train_ridge, y_train)\n",
    "\n",
    "\n",
    "best_ridge = grid.best_estimator_\n",
    "\n",
    "# Predict in log(shifted score) space\n",
    "y_test_pred_log = best_ridge.predict(X_test_ridge)\n",
    "# Metrics in LOG space\n",
    "mae_log = mean_absolute_error(y_test, y_test_pred_log)\n",
    "\n",
    "y_test_pred_log = best_ridge.predict(X_test_ridge)\n",
    "# log metrics\n",
    "mae_log  = mean_absolute_error(y_test, y_test_pred_log)\n",
    "# back to raw\n",
    "y_test_raw      = np.exp(y_test)      + min_score - 1\n",
    "y_test_pred_raw = np.exp(y_test_pred_log) + min_score - 1\n",
    "mae_raw  = mean_absolute_error(y_test_raw, y_test_pred_raw)\n",
    "print(\"Ridge MAE (log):\", mae_log)\n",
    "print(\"Ridge MAE (raw):\", mae_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argument and Defense for Ridge:\n",
    "\n",
    "1. Theoretically most appropritate model\n",
    "    - Given that this is very high dimensional with TF-IDF features, this would not be a tree based problem (Random Forest, XGBoost)\n",
    "\n",
    "2. I guess academically most academically appropriate model, its standard in ML \n",
    "\n",
    "3. Better preformance compared to linear regresion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
